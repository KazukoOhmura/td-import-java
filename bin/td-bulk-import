#!/usr/bin/env ruby
# -*- coding: utf-8 -*-

# td-bulk-import test command

require 'rubygems' unless defined?(gem)
require 'td/config'

HERE = File.dirname(__FILE__)
PART_SPLIT_SIZE = 16*1024*1024

def bulk_import_upload_parts2(op)
  opts = upload_parts2_config(op)

  # java command
  javacmd = 'java'

  # make jvm options
  jvm_opts = []
  jvm_opts << "-Xmx1024m" # TODO

  # find java/*.jar and td.jar
  libjars = Dir.glob("#{HERE}/../src/test/resources/java/**/*.jar")
  found = libjars.find { |path| File.basename(path) =~ /^td-bulk-import/ }
  if found.nil?
    $stderr.puts "You should build td-bulk-import first. Please type 'mvn package -Dmaven.test.skip=true'"
    exit
  end
  td_command_jar = libjars.delete(found)

  # make application options
  app_opts = []
  app_opts << "-cp \"#{td_command_jar}\""

  # make system properties
  sysprops = []
  sysprops.concat(upload_parts2_sysprops(opts))

  # make application arguments
  app_args = []
  app_args << 'com.treasure_data.bulk_import.Main'
  app_args << 'upload_parts'
  app_args << opts[22]

  # TODO consider parameters including spaces; don't use join(' ')
  command = "#{javacmd} #{jvm_opts.join(' ')} #{app_opts.join(' ')} #{sysprops.join(' ')} #{app_args.join(' ')}"

  exec command
end

def bulk_import_prepare_parts2(op)
  opts = prepare_parts2_config(op)

  # java command
  javacmd = 'java'

  # make jvm options
  jvm_opts = []
  jvm_opts << "-Xmx1024m" # TODO

  # find java/*.jar and td.jar
  libjars = Dir.glob("#{HERE}/../src/test/resources/java/**/*.jar")
  found = libjars.find { |path| File.basename(path) =~ /^td-bulk-import/ }
  if found.nil?
    $stderr.puts "You should build td-bulk-import first. Please type 'mvn package -Dmaven.test.skip=true'"
    exit
  end
  td_command_jar = libjars.delete(found)

  # make application options
  app_opts = []
  app_opts << "-cp \"#{td_command_jar}\""

  # make system properties
  sysprops = []
  sysprops.concat(prepare_parts2_sysprops(opts))

  # make application arguments
  app_args = []
  app_args << 'com.treasure_data.bulk_import.Main'
  app_args << 'prepare_parts'
  app_args << opts[19]

  # TODO consider parameters including spaces; don't use join(' ')
  command = "#{javacmd} #{jvm_opts.join(' ')} #{app_opts.join(' ')} #{sysprops.join(' ')} #{app_args.join(' ')}"

  exec command
end

def set_http_proxy(sysprops)
  http_proxy = ENV['HTTP_PROXY']
  if http_proxy
    if http_proxy =~ /\Ahttp:\/\/(.*)\z/
      http_proxy = $~[1]
    end
    proxy_host, proxy_port = http_proxy.split(':',2)
    proxy_port = (proxy_port ? proxy_port.to_i : 80)

    sysprops << "-Dhttp.proxyHost=#{proxy_host}"
    sysprops << "-Dhttp.proxyPost=#{proxy_port}"
  end
end

def prepare_parts2_sysprops(opts)
  sysprops = []

  # set http_proxy
  set_http_proxy(sysprops)

  sysprops << "-Dtd.bulk_import.prepare_parts.format=#{opts[0]}"
  sysprops << "-Dtd.bulk_import.prepare_parts.compression=#{opts[1]}"
  sysprops << "-Dtd.bulk_import.prepare_parts.encoding=#{opts[2]}"
  sysprops << "-Dtd.bulk_import.prepare_parts.time-column=#{opts[3]}"
  sysprops << "-Dtd.bulk_import.prepare_parts.time-format=#{opts[4]}"
  sysprops << "-Dtd.bulk_import.prepare_parts.time-value=#{opts[5].to_s}" if opts[5]
  sysprops << "-Dtd.bulk_import.prepare_parts.output-dir=#{opts[6]}"
  sysprops << "-Dtd.bulk_import.prepare_parts.split-size=#{opts[7]}"
  sysprops << "-Dtd.bulk_import.prepare_parts.error-record-output=#{opts[8]}" if opts[8]
  sysprops << "-Dtd.bulk_import.prepare_parts.dry-run=#{opts[9]}"
  sysprops << "-Dtd.bulk_import.prepare_parts.delimiter=#{opts[10]}"
  sysprops << "-Dtd.bulk_import.prepare_parts.quote=#{opts[11]}"
  sysprops << "-Dtd.bulk_import.prepare_parts.newline=#{opts[12]}"
  sysprops << "-Dtd.bulk_import.prepare_parts.column-header=#{opts[13]}" if opts[13]
  sysprops << "-Dtd.bulk_import.prepare_parts.columns=#{opts[14]}" if opts[14]
  sysprops << "-Dtd.bulk_import.prepare_parts.column-types=#{opts[15]}" if opts[15]
  sysprops << "-Dtd.bulk_import.prepare_parts.type-conversion-error=#{opts[16]}" if opts[16]
  sysprops << "-Dtd.bulk_import.prepare_parts.exclude-columns=#{opts[17]}" if opts[17]
  sysprops << "-Dtd.bulk_import.prepare_parts.only-columns=#{opts[18]}" if opts[18]

  p sysprops

  sysprops
end

def upload_parts2_sysprops(opts, with_prepare = false)
  sysprops = []

  # set http_proxy
  set_http_proxy(sysprops)

  if with_prepare
    sysprops << "-Dtd.bulk_import.prepare_parts.format=#{opts[0]}"
    sysprops << "-Dtd.bulk_import.prepare_parts.compression=#{opts[1]}"
    sysprops << "-Dtd.bulk_import.prepare_parts.encoding=#{opts[2]}"
    sysprops << "-Dtd.bulk_import.prepare_parts.time-column=#{opts[3]}"
    sysprops << "-Dtd.bulk_import.prepare_parts.time-format=#{opts[4]}"
    sysprops << "-Dtd.bulk_import.prepare_parts.time-value=#{opts[5].to_s}" if opts[5]
    sysprops << "-Dtd.bulk_import.prepare_parts.output-dir=#{opts[6]}"
    sysprops << "-Dtd.bulk_import.prepare_parts.split-size=#{opts[7]}"
    sysprops << "-Dtd.bulk_import.prepare_parts.error-record-output=#{opts[8]}" if opts[8]
    sysprops << "-Dtd.bulk_import.prepare_parts.dry-run=#{opts[9]}"
    sysprops << "-Dtd.bulk_import.prepare_parts.delimiter=#{opts[10]}"
    sysprops << "-Dtd.bulk_import.prepare_parts.quote=#{opts[11]}"
    sysprops << "-Dtd.bulk_import.prepare_parts.newline=#{opts[12]}"
    sysprops << "-Dtd.bulk_import.prepare_parts.column-header=#{opts[13]}" if opts[13]
    sysprops << "-Dtd.bulk_import.prepare_parts.columns=#{opts[14]}" if opts[14]
    sysprops << "-Dtd.bulk_import.prepare_parts.column-types=#{opts[15]}" if opts[15]
    sysprops << "-Dtd.bulk_import.prepare_parts.type-conversion-error=#{opts[16]}" if opts[16]
    sysprops << "-Dtd.bulk_import.prepare_parts.exclude-columns=#{opts[17]}" if opts[17]
    sysprops << "-Dtd.bulk_import.prepare_parts.only-columns=#{opts[18]}" if opts[18]
  end

  sysprops << "-Dtd.bulk_import.upload_parts.auto-perform=#{opts[19]}"
  sysprops << "-Dtd.bulk_import.upload_parts.auto-commit=#{opts[20]}"
  sysprops << "-Dtd.bulk_import.upload_parts.parallel=#{opts[21]}"
  sysprops << "-Dtd.bulk_import.upload_parts.retrycount=10"
  sysprops << "-Dtd.bulk_import.upload_parts.waitsec=1"
  sysprops << "-Dtd.api.key=#{TreasureData::Config.apikey}"
  sysprops
end

def prepare_parts2_config(op)
  format = 'csv'
  compress = 'none'
  encoding = 'utf-8'
  time_column = 'time'
  time_format = nil
  time_value = nil
  outdir = nil
  split_size_kb = PART_SPLIT_SIZE / 1024  # kb
  error_record_output = nil
  dry_run = false

  delimiter = ','
  quote = "DOUBLE"
  newline = 'CRLF'
  column_header = nil
  columns = nil
  column_types = nil
  type_conversion_error = 'skip'
  exclude_columns = nil
  only_columns = nil

  # prepare_parts
  op.on('-f', '--format NAME', 'source file format [csv, tsv]; default=csv') {|s|
    format = s
  }
  op.on('-C', '--compress TYPE', 'compressed type [gzip, none]; default=auto detect') {|s|
    compress = s
  }
  op.on('-e', '--encoding TYPE', 'encoding type [utf-8]') {|s|
    encoding = s
  }
  op.on('-t', '--time-column NAME', 'name of the time column') {|s|
    time_column = s
  }
  op.on('-T', '--time-format', 'STRF_FORMAT; default=auto detect') {|s|
    time_format = s
  }
  op.on('--time-value TIME', 'long value of the time column') {|s|
    if s.to_i.to_s == s
      time_value = s.to_i
    else
      require 'time'
      time_value = Time.parse(s).to_i
    end
  }
  op.on('-o', '--output DIR', 'output directory') {|s|
    outdir = s
  }
  op.on('-s', '--split-size SIZE_IN_KB', "size of each parts (default: #{split_size_kb})", Integer) {|i|
    split_size_kb = i
  }
  op.on('--error-record-output FILE', 'error records output file; default=NULL output stream') {|s|
    error_record_outdir = s
  }
  op.on('--dry-run', 'show samples as JSON and exit', FalseClass) {|b|
    dry_run = b
  }
  op.on('--delimiter CHAR', 'delimiter CHAR; default="," at csv, "\t" at tsv') {|s|
    delimiter = s
  }
  op.on('--quote', 'quote [DOUBLE, SINGLE]; default=DOUBLE') {|s|
    quote = s
  }
  op.on('--newline', 'newline [CRLR, LR, CR];  default=CRLF') {|s|
    newline = s
  }
  op.on('-H', '--column-header', 'first line includes column names', TrueClass) {|b|
    column_header = b
  }
  op.on('-h', '--columns NAME,NAME,...', 'column names (use --column-header instead if the first line has column names)') {|s|
    columns = s
  }
  op.on('--column-types TYPE,TYPE,...', 'column types [string, int, long]') {|s|
    column_types = s
  }
  op.on('--type-conversion-error TYPE', 'type conversion error [skip,null]; default=skip') {|s|
    type_conversion_error = s
  }
  op.on('--exclude-columns NAME,NAME,...', 'exclude columns') {|s|
    exclude_columns = s
  }
  op.on('--only-columns NAME,NAME,...', 'only columns') {|s|
    only_columns = s
  }

  op.parse!(ARGV)
  files = ARGV
  files = [files] unless files.is_a?(Array) # TODO ruby 1.9

  # options validation
  #unless column_types
  #  $stderr.puts "--column-types TYPE,TYPE,... option is required."
  #  exit 1
  #end
  unless outdir
    $stderr.puts "-o, --output DIR option is required."
    exit 1
  end

  return [ format, compress, encoding,
    time_column, time_format, time_value,
    outdir,  split_size_kb, error_record_output, dry_run,
    delimiter, quote, newline, column_header, columns, column_types,
    type_conversion_error, exclude_columns, only_columns, files ]
end

def upload_parts2_config(op)
  format = 'csv'
  compress = 'none'
  encoding = 'utf-8'
  time_column = 'time'
  time_format = nil
  time_value = nil
  outdir = nil
  split_size_kb = PART_SPLIT_SIZE / 1024  # kb
  error_record_output = nil
  dry_run = false

  delimiter = ','
  quote = 'DOUBLE'
  newline = 'CRLF'
  column_header = nil
  columns = nil
  column_types = nil
  type_conversion_error = 'skip'
  exclude_columns = nil
  only_columns = nil

  auto_perform = false
  auto_commit = false
  parallel = 2

  # prepare_parts
  op.on('-f', '--format NAME', 'source file format [csv, tsv]; default=csv') {|s|
    format = s
  }
  op.on('-C', '--compress TYPE', 'compressed type [gzip, none]; default=auto detect') {|s|
    compress = s
  }
  op.on('-e', '--encoding TYPE', 'encoding type [utf-8]') {|s|
    encoding = s
  }
  op.on('-t', '--time-column NAME', 'name of the time column') {|s|
    time_column = s
  }
  op.on('-T', '--time-format', 'STRF_FORMAT; default=auto detect') {|s|
    time_format = s
  }
  op.on('--time-value TIME', 'long value of the time column') {|s|
    if s.to_i.to_s == s
      time_value = s.to_i
    else
      require 'time'
      time_value = Time.parse(s).to_i
    end
  }
  op.on('-o', '--output [DIR]', 'output directory', "when use fluent upload") {|s|
    outdir = s
  }
  op.on('-s', '--split-size SIZE_IN_KB', "size of each parts (default: #{split_size_kb})", Integer) {|i|
    split_size_kb = i
  }
  op.on('--error-record-output FILE', 'error records output file; default=NULL output stream') {|s|
    error_record_outdir = s
  }
  op.on('--dry-run', 'show samples as JSON and exit', FalseClass) {|b|
    dry_run = b
  }
  op.on('--delimiter CHAR', 'delimiter CHAR; default="," at csv, "\t" at tsv') {|s|
    delimiter = s
  }
  op.on('--quote', 'quote [DOUBLE, SINGLE]; default=DOUBLE') {|s|
    quote = s
  }
  op.on('--newline', 'newline [CRLR, LR, CR];  default=CRLF') {|s|
    newline = s
  }
  op.on('-H', '--column-header', 'first line includes column names', TrueClass) {|b|
    column_header = b
  }
  op.on('-h', '--columns NAME,NAME,...', 'column names (use --column-header instead if the first line has column names)') {|s|
    columns = s
  }
  op.on('--column-types TYPE,TYPE,...', 'column types [string, int, long]') {|s|
    column_types = s
  }
  op.on('--type-conversion-error TYPE', 'type conversion error [skip,null]; default=skip') {|s|
    type_conversion_error = s
  }
  op.on('--exclude-columns NAME,NAME,...', 'exclude columns') {|s|
    exclude_columns = s
  }
  op.on('--only-columns NAME,NAME,...', 'only columns') {|s|
    only_columns = s
  }
  # upload_parts
  op.on('--auto-perform', 'perform bulk import job automatically', TrueClass) {|b|
    auto_perform = b
  }
  op.on('--auto-commit', 'commit bulk import job automatically', FalseClass) {|b|
    auto_commit = b
  }
  op.on('--parallel NUM', 'upload in parallel (default: 2; max 8)', Integer) {|i|
    parallel = i
  }

  op.parse!(ARGV)
  files = ARGV
  files = [files] unless files.is_a?(Array) # TODO ruby 1.9

  # options validation
  #unless column_types
  #  $stderr.puts "--column-types TYPE,TYPE,... option is required."
  #  exit 1
  #end

  return [ format, compress, encoding,
    time_column, time_format, time_value,
    outdir,  split_size_kb, error_record_output, dry_run,
    delimiter, quote, newline, column_header, columns, column_types,
    type_conversion_error, exclude_columns, only_columns,
    auto_perform, auto_commit, parallel, files ]
end

require 'optparse'

command = ARGV.shift
op = OptionParser.new
op.banner = <<EOF
usage: #{File.basename($0)} [prepare_parts2|upload_parts2] [OPTIONS]

OPTIONS are same as td command.
EOF

case command
when 'prepare_parts2'
  bulk_import_prepare_parts2(op)
when 'upload_parts2'
  bulk_import_upload_parts2(op)
else
  $stderr.puts "Unknown command: #{command}"
end
